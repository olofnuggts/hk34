{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afbe4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# This converts the images (0-255) into Tensors (0.0 - 1.0)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load training data\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# Create a loader to feed data in batches of 32 images at a time\n",
    "train_loader: DataLoader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader: DataLoader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b2e4b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Grab the raw image tensor\n",
    "image = train_data.data[4]\n",
    "label = train_data.targets[4]\n",
    "\n",
    "# 2. Plot it\n",
    "plt.imshow(image, cmap=\"gray\") # cmap=\"gray\" forces black & white\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\") # Optional: Hides the ruler numbers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86e61875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "neuralNetwork = NeuralNetwork().to(device)\n",
    "neuralNetwork\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# CrossEntropyLoss is standard for classification (choosing 1 out of N categories)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(neuralNetwork.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8edbf7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 2.30520, Acc: 8.80% | Test Loss: 2.30360, Test Acc: 14.00%\n",
      "Epoch: 100 | Loss: 2.25080, Acc: 35.30% | Test Loss: 2.24424, Test Acc: 41.00%\n",
      "Epoch: 200 | Loss: 2.07757, Acc: 63.70% | Test Loss: 2.06719, Test Acc: 65.00%\n",
      "Epoch: 300 | Loss: 1.24070, Acc: 76.10% | Test Loss: 1.23687, Test Acc: 75.00%\n",
      "Epoch: 400 | Loss: 0.59877, Acc: 85.00% | Test Loss: 0.65402, Test Acc: 79.00%\n",
      "Epoch: 500 | Loss: 0.43112, Acc: 87.90% | Test Loss: 0.49091, Test Acc: 85.00%\n",
      "Epoch: 600 | Loss: 0.35345, Acc: 89.60% | Test Loss: 0.40834, Test Acc: 85.00%\n",
      "Epoch: 700 | Loss: 0.30433, Acc: 91.90% | Test Loss: 0.35344, Test Acc: 88.00%\n",
      "Epoch: 800 | Loss: 0.26785, Acc: 92.90% | Test Loss: 0.31640, Test Acc: 89.00%\n",
      "Epoch: 900 | Loss: 0.23838, Acc: 93.60% | Test Loss: 0.29072, Test Acc: 88.00%\n",
      "Epoch: 1000 | Loss: 0.21309, Acc: 94.30% | Test Loss: 0.27089, Test Acc: 88.00%\n",
      "Epoch: 1100 | Loss: 0.19091, Acc: 94.50% | Test Loss: 0.25494, Test Acc: 89.00%\n",
      "Epoch: 1200 | Loss: 0.17091, Acc: 94.90% | Test Loss: 0.24378, Test Acc: 90.00%\n",
      "Epoch: 1300 | Loss: 0.15270, Acc: 95.70% | Test Loss: 0.23466, Test Acc: 89.00%\n",
      "Epoch: 1400 | Loss: 0.13588, Acc: 96.00% | Test Loss: 0.22751, Test Acc: 89.00%\n",
      "Epoch: 1500 | Loss: 0.12045, Acc: 97.00% | Test Loss: 0.22195, Test Acc: 90.00%\n",
      "Epoch: 1600 | Loss: 0.10643, Acc: 97.30% | Test Loss: 0.21697, Test Acc: 89.00%\n",
      "Epoch: 1700 | Loss: 0.09370, Acc: 97.60% | Test Loss: 0.21342, Test Acc: 89.00%\n",
      "Epoch: 1800 | Loss: 0.08215, Acc: 98.00% | Test Loss: 0.21140, Test Acc: 88.00%\n",
      "Epoch: 1900 | Loss: 0.07185, Acc: 98.50% | Test Loss: 0.20927, Test Acc: 89.00%\n",
      "Epoch: 2000 | Loss: 0.06279, Acc: 98.60% | Test Loss: 0.20688, Test Acc: 89.00%\n",
      "Epoch: 2100 | Loss: 0.05494, Acc: 98.90% | Test Loss: 0.20540, Test Acc: 90.00%\n",
      "Epoch: 2200 | Loss: 0.04817, Acc: 99.50% | Test Loss: 0.20419, Test Acc: 90.00%\n",
      "Epoch: 2300 | Loss: 0.04234, Acc: 99.70% | Test Loss: 0.20293, Test Acc: 90.00%\n",
      "Epoch: 2400 | Loss: 0.03733, Acc: 99.80% | Test Loss: 0.20203, Test Acc: 90.00%\n",
      "Epoch: 2500 | Loss: 0.03306, Acc: 99.90% | Test Loss: 0.20146, Test Acc: 90.00%\n",
      "Epoch: 2600 | Loss: 0.02939, Acc: 99.90% | Test Loss: 0.20060, Test Acc: 90.00%\n",
      "Epoch: 2700 | Loss: 0.02626, Acc: 100.00% | Test Loss: 0.20023, Test Acc: 90.00%\n",
      "Epoch: 2800 | Loss: 0.02356, Acc: 100.00% | Test Loss: 0.20009, Test Acc: 91.00%\n",
      "Epoch: 2900 | Loss: 0.02125, Acc: 100.00% | Test Loss: 0.20002, Test Acc: 91.00%\n",
      "Epoch: 3000 | Loss: 0.01925, Acc: 100.00% | Test Loss: 0.19998, Test Acc: 91.00%\n",
      "Epoch: 3100 | Loss: 0.01752, Acc: 100.00% | Test Loss: 0.19997, Test Acc: 91.00%\n",
      "Epoch: 3200 | Loss: 0.01601, Acc: 100.00% | Test Loss: 0.20017, Test Acc: 91.00%\n",
      "Epoch: 3300 | Loss: 0.01469, Acc: 100.00% | Test Loss: 0.20049, Test Acc: 91.00%\n",
      "Epoch: 3400 | Loss: 0.01353, Acc: 100.00% | Test Loss: 0.20067, Test Acc: 91.00%\n",
      "Epoch: 3500 | Loss: 0.01250, Acc: 100.00% | Test Loss: 0.20092, Test Acc: 91.00%\n",
      "Epoch: 3600 | Loss: 0.01159, Acc: 100.00% | Test Loss: 0.20104, Test Acc: 91.00%\n",
      "Epoch: 3700 | Loss: 0.01078, Acc: 100.00% | Test Loss: 0.20122, Test Acc: 91.00%\n",
      "Epoch: 3800 | Loss: 0.01006, Acc: 100.00% | Test Loss: 0.20168, Test Acc: 91.00%\n",
      "Epoch: 3900 | Loss: 0.00940, Acc: 100.00% | Test Loss: 0.20205, Test Acc: 91.00%\n",
      "Epoch: 4000 | Loss: 0.00882, Acc: 100.00% | Test Loss: 0.20236, Test Acc: 91.00%\n",
      "Epoch: 4100 | Loss: 0.00829, Acc: 100.00% | Test Loss: 0.20256, Test Acc: 92.00%\n",
      "Epoch: 4200 | Loss: 0.00781, Acc: 100.00% | Test Loss: 0.20300, Test Acc: 92.00%\n",
      "Epoch: 4300 | Loss: 0.00737, Acc: 100.00% | Test Loss: 0.20337, Test Acc: 92.00%\n",
      "Epoch: 4400 | Loss: 0.00697, Acc: 100.00% | Test Loss: 0.20373, Test Acc: 92.00%\n",
      "Epoch: 4500 | Loss: 0.00661, Acc: 100.00% | Test Loss: 0.20426, Test Acc: 92.00%\n",
      "Epoch: 4600 | Loss: 0.00627, Acc: 100.00% | Test Loss: 0.20477, Test Acc: 92.00%\n",
      "Epoch: 4700 | Loss: 0.00597, Acc: 100.00% | Test Loss: 0.20522, Test Acc: 92.00%\n",
      "Epoch: 4800 | Loss: 0.00568, Acc: 100.00% | Test Loss: 0.20567, Test Acc: 92.00%\n",
      "Epoch: 4900 | Loss: 0.00542, Acc: 100.00% | Test Loss: 0.20601, Test Acc: 92.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Add channel dimension (1) expected by Conv2d: (batch, 1, 28, 28)\n",
    "X_train = (train_data.data[:1000].unsqueeze(1).float() / 255.0).to(device)\n",
    "X_test = (test_data.data[:100].unsqueeze(1).float() / 255.0).to(device)\n",
    "y_train = train_data.targets[:1000].long().to(device)\n",
    "y_test = test_data.targets[:100].long().to(device)\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    neuralNetwork.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_logits = neuralNetwork(X_train)\n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) \n",
    "\n",
    "    # Calculate loss/accuracy\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    acc = accuracy_score(y_true=y_train.cpu(), y_pred=y_pred.cpu())\n",
    "\n",
    "    # Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    neuralNetwork.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Forward pass\n",
    "        test_logits = neuralNetwork(X_test)\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        # Calculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_score(y_true=y_test.cpu(), y_pred=test_pred.cpu())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2%} | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "517ec23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "DEBUG: Data Range is 0.00 to 1.00\n",
      "Train Loss: 0.01274 | Train Acc: 99.59%\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Loss: 0.01064 | Train Acc: 99.64%\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Loss: 0.00740 | Train Acc: 99.74%\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Loss: 0.00814 | Train Acc: 99.72%\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Loss: 0.00619 | Train Acc: 99.80%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    neuralNetwork.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        # --- SANITY CHECK (Verifies data is correct) ---\n",
    "        if epoch == 0 and batch == 0:\n",
    "            print(f\"DEBUG: Data Range is {X.min():.2f} to {X.max():.2f}\")\n",
    "            if X.max() > 1.0:\n",
    "                print(\"!! WARNING: Data is not normalized (0-255). Check transforms !!\")\n",
    "        # -----------------------------------------------\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward\n",
    "        y_pred = neuralNetwork(X)\n",
    "        \n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Accuracy\n",
    "        train_acc += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader.dataset) #type: ignore\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4210e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad(): # Tell PyTorch we don't need gradients for this (saves memory)\n",
    "    images = images.to(device)  # Move images to the same device as the model\n",
    "    outputs = neuralNetwork(images)\n",
    "    # The prediction is the index with the highest score\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Show the first 5 images and their predictions\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n",
    "    # Convert tensor image back to numpy for display\n",
    "    # .cpu() moves it back to system memory\n",
    "    img = images[i].cpu().squeeze().numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"Pred: {predicted[i].item()}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
