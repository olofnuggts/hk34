{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbe4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# This converts the images (0-255) into Tensors (0.0 - 1.0)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load training data\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# Create a loader to feed data in batches of 32 images at a time\n",
    "train_loader: DataLoader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader: DataLoader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2e4b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Grab the raw image tensor\n",
    "image = train_data.data[4]\n",
    "label = train_data.targets[4]\n",
    "\n",
    "# 2. Plot it\n",
    "plt.imshow(image, cmap=\"gray\") # cmap=\"gray\" forces black & white\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\") # Optional: Hides the ruler numbers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e61875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n",
      "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "neuralNetwork = NeuralNetwork().to(device)\n",
    "neuralNetwork\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca8f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# CrossEntropyLoss is standard for classification (choosing 1 out of N categories)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(neuralNetwork.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8edbf7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 2.30592, Acc: 8.60% | Test Loss: 2.31494, Test Acc: 8.00%\n",
      "Epoch: 100 | Loss: 2.29616, Acc: 9.50% | Test Loss: 2.30468, Test Acc: 8.00%\n",
      "Epoch: 200 | Loss: 2.28791, Acc: 10.90% | Test Loss: 2.29599, Test Acc: 8.00%\n",
      "Epoch: 300 | Loss: 2.28021, Acc: 13.10% | Test Loss: 2.28796, Test Acc: 11.00%\n",
      "Epoch: 400 | Loss: 2.27233, Acc: 18.30% | Test Loss: 2.27977, Test Acc: 16.00%\n",
      "Epoch: 500 | Loss: 2.26380, Acc: 25.00% | Test Loss: 2.27095, Test Acc: 27.00%\n",
      "Epoch: 600 | Loss: 2.25427, Acc: 33.50% | Test Loss: 2.26120, Test Acc: 32.00%\n",
      "Epoch: 700 | Loss: 2.24347, Acc: 38.80% | Test Loss: 2.25020, Test Acc: 35.00%\n",
      "Epoch: 800 | Loss: 2.23122, Acc: 42.70% | Test Loss: 2.23765, Test Acc: 39.00%\n",
      "Epoch: 900 | Loss: 2.21728, Acc: 45.90% | Test Loss: 2.22351, Test Acc: 43.00%\n",
      "Epoch: 1000 | Loss: 2.20123, Acc: 49.30% | Test Loss: 2.20737, Test Acc: 44.00%\n",
      "Epoch: 1100 | Loss: 2.18259, Acc: 52.30% | Test Loss: 2.18865, Test Acc: 46.00%\n",
      "Epoch: 1200 | Loss: 2.16067, Acc: 53.70% | Test Loss: 2.16677, Test Acc: 48.00%\n",
      "Epoch: 1300 | Loss: 2.13476, Acc: 56.50% | Test Loss: 2.14087, Test Acc: 49.00%\n",
      "Epoch: 1400 | Loss: 2.10412, Acc: 59.10% | Test Loss: 2.11014, Test Acc: 52.00%\n",
      "Epoch: 1500 | Loss: 2.06754, Acc: 60.80% | Test Loss: 2.07339, Test Acc: 56.00%\n",
      "Epoch: 1600 | Loss: 2.02359, Acc: 61.90% | Test Loss: 2.02944, Test Acc: 59.00%\n",
      "Epoch: 1700 | Loss: 1.97078, Acc: 63.00% | Test Loss: 1.97673, Test Acc: 59.00%\n",
      "Epoch: 1800 | Loss: 1.90746, Acc: 64.60% | Test Loss: 1.91364, Test Acc: 61.00%\n",
      "Epoch: 1900 | Loss: 1.83213, Acc: 65.50% | Test Loss: 1.83854, Test Acc: 62.00%\n",
      "Epoch: 2000 | Loss: 1.74376, Acc: 67.40% | Test Loss: 1.75063, Test Acc: 66.00%\n",
      "Epoch: 2100 | Loss: 1.64265, Acc: 68.70% | Test Loss: 1.65011, Test Acc: 66.00%\n",
      "Epoch: 2200 | Loss: 1.53135, Acc: 69.90% | Test Loss: 1.53961, Test Acc: 69.00%\n",
      "Epoch: 2300 | Loss: 1.41390, Acc: 70.90% | Test Loss: 1.42384, Test Acc: 71.00%\n",
      "Epoch: 2400 | Loss: 1.29608, Acc: 73.00% | Test Loss: 1.30864, Test Acc: 72.00%\n",
      "Epoch: 2500 | Loss: 1.18373, Acc: 75.00% | Test Loss: 1.19948, Test Acc: 76.00%\n",
      "Epoch: 2600 | Loss: 1.08146, Acc: 76.40% | Test Loss: 1.10074, Test Acc: 77.00%\n",
      "Epoch: 2700 | Loss: 0.99170, Acc: 77.20% | Test Loss: 1.01416, Test Acc: 78.00%\n",
      "Epoch: 2800 | Loss: 0.91478, Acc: 78.00% | Test Loss: 0.93986, Test Acc: 77.00%\n",
      "Epoch: 2900 | Loss: 0.84960, Acc: 78.00% | Test Loss: 0.87672, Test Acc: 78.00%\n",
      "Epoch: 3000 | Loss: 0.79445, Acc: 79.00% | Test Loss: 0.82322, Test Acc: 78.00%\n",
      "Epoch: 3100 | Loss: 0.74753, Acc: 80.00% | Test Loss: 0.77776, Test Acc: 78.00%\n",
      "Epoch: 3200 | Loss: 0.70715, Acc: 81.30% | Test Loss: 0.73907, Test Acc: 79.00%\n",
      "Epoch: 3300 | Loss: 0.67198, Acc: 82.50% | Test Loss: 0.70585, Test Acc: 79.00%\n",
      "Epoch: 3400 | Loss: 0.64103, Acc: 83.10% | Test Loss: 0.67682, Test Acc: 79.00%\n",
      "Epoch: 3500 | Loss: 0.61353, Acc: 83.50% | Test Loss: 0.65124, Test Acc: 79.00%\n",
      "Epoch: 3600 | Loss: 0.58893, Acc: 84.10% | Test Loss: 0.62838, Test Acc: 80.00%\n",
      "Epoch: 3700 | Loss: 0.56668, Acc: 84.70% | Test Loss: 0.60798, Test Acc: 80.00%\n",
      "Epoch: 3800 | Loss: 0.54638, Acc: 85.10% | Test Loss: 0.58963, Test Acc: 81.00%\n",
      "Epoch: 3900 | Loss: 0.52780, Acc: 85.50% | Test Loss: 0.57299, Test Acc: 81.00%\n",
      "Epoch: 4000 | Loss: 0.51074, Acc: 86.00% | Test Loss: 0.55768, Test Acc: 81.00%\n",
      "Epoch: 4100 | Loss: 0.49498, Acc: 86.10% | Test Loss: 0.54350, Test Acc: 82.00%\n",
      "Epoch: 4200 | Loss: 0.48036, Acc: 86.50% | Test Loss: 0.53022, Test Acc: 84.00%\n",
      "Epoch: 4300 | Loss: 0.46681, Acc: 86.70% | Test Loss: 0.51780, Test Acc: 84.00%\n",
      "Epoch: 4400 | Loss: 0.45421, Acc: 87.00% | Test Loss: 0.50622, Test Acc: 84.00%\n",
      "Epoch: 4500 | Loss: 0.44248, Acc: 87.80% | Test Loss: 0.49536, Test Acc: 85.00%\n",
      "Epoch: 4600 | Loss: 0.43151, Acc: 88.00% | Test Loss: 0.48516, Test Acc: 85.00%\n",
      "Epoch: 4700 | Loss: 0.42124, Acc: 88.20% | Test Loss: 0.47550, Test Acc: 85.00%\n",
      "Epoch: 4800 | Loss: 0.41160, Acc: 88.50% | Test Loss: 0.46647, Test Acc: 85.00%\n",
      "Epoch: 4900 | Loss: 0.40252, Acc: 88.70% | Test Loss: 0.45789, Test Acc: 85.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Add channel dimension (1) expected by Conv2d: (batch, 1, 28, 28)\n",
    "X_train = (train_data.data[:1000].unsqueeze(1).float() / 255.0).to(device)\n",
    "X_test = (test_data.data[:100].unsqueeze(1).float() / 255.0).to(device)\n",
    "y_train = train_data.targets[:1000].long().to(device)\n",
    "y_test = test_data.targets[:100].long().to(device)\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    neuralNetwork.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_logits = neuralNetwork(X_train)\n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) \n",
    "\n",
    "    # Calculate loss/accuracy\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    acc = accuracy_score(y_true=y_train.cpu(), y_pred=y_pred.cpu())\n",
    "\n",
    "    # Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    neuralNetwork.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Forward pass\n",
    "        test_logits = neuralNetwork(X_test)\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        # Calculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_score(y_true=y_test.cpu(), y_pred=test_pred.cpu())\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2%} | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517ec23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "DEBUG: Data Range is 0.00 to 1.00\n",
      "Train Loss: 2.24308 | Train Acc: 46.20%\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Loss: 1.63861 | Train Acc: 70.23%\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Loss: 0.59559 | Train Acc: 84.28%\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Loss: 0.40326 | Train Acc: 88.45%\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Loss: 0.34235 | Train Acc: 89.97%\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Loss: 0.30800 | Train Acc: 90.96%\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Loss: 0.28258 | Train Acc: 91.60%\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Loss: 0.26038 | Train Acc: 92.26%\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Loss: 0.24085 | Train Acc: 92.85%\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Loss: 0.22279 | Train Acc: 93.36%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    neuralNetwork.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    # X is the images y is the labels\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        # --- SANITY CHECK (Verifies data is correct) ---\n",
    "        if epoch == 0 and batch == 0:\n",
    "            print(f\"DEBUG: Data Range is {X.min():.2f} to {X.max():.2f}\")\n",
    "            if X.max() > 1.0:\n",
    "                print(\"!! WARNING: Data is not normalized (0-255). Check transforms !!\")\n",
    "        # -----------------------------------------------\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward\n",
    "        y_pred = neuralNetwork(X)\n",
    "        \n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Accuracy\n",
    "        train_acc += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader.dataset) #type: ignore\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4210e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad(): # Tell PyTorch we don't need gradients for this (saves memory)\n",
    "    images = images.to(device)  # Move images to the same device as the model\n",
    "    outputs = neuralNetwork(images)\n",
    "    # The prediction is the index with the highest score\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Show the first 5 images and their predictions\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n",
    "    # Convert tensor image back to numpy for display\n",
    "    # .cpu() moves it back to system memory\n",
    "    img = images[i].cpu().squeeze().numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    is_correct = predicted[i].item() == labels[i].item()\n",
    "    ax.set_title(f\"Pred: {predicted[i].item()}\\n {'Correct' if is_correct else 'Incorrect'}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
